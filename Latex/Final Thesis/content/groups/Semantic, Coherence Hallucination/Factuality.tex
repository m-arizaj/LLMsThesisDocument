\subsection{Factuality}

\textbf{Factuality} in the context of Large Language Models (LLMs) refers to the extent to which the information or answers provided by the model align with \textbf{real-world truths and verifiable facts}.

Evaluating factuality is a critical component of LLM assessment. It measures the model's ability to:
\begin{itemize}
    \item Maintain consistency with known facts.
    \item Avoid generating misleading or false information, a phenomenon known as ``factual hallucination.''
    \item Effectively learn and recall factual knowledge.
\end{itemize}

\subsubsection*{Purpose}
The primary purpose of evaluating factuality is to \textbf{ensure trust} and enable the efficient use of LLMs. Factuality significantly impacts the reliability of downstream applications. Inconsistent or incorrect information can lead to substantial misunderstandings, making this metric crucial.

\subsubsection*{Applications}
This metric is applied across general LLM evaluation and specific high-stakes domains:
\begin{itemize}
    \item \textbf{Question Answering (QA)}: Ensuring answers are grounded in reality.
    \item \textbf{Text Summarization}: Ensuring the summary remains factually consistent with the source.
    \item \textbf{Automated Fact-Checking}: Using models to verify claims.
    \item \textbf{Information Extraction}: Retrieving accurate data points.
\end{itemize}

\subsubsection*{Advantages}
\begin{itemize}
    \item \textbf{Builds Trust}: Directly measures the reliability and truthfulness of a model, which is essential for user trust.
    \item \textbf{Critical for Applications}: Serves as a gate for deploying LLMs in information-sensitive fields like medicine, finance, and education.
    \item \textbf{Targets Hallucination}: Provides a direct way to quantify and track a model's tendency to ``hallucinate'' or fabricate information.
\end{itemize}

\subsubsection*{Limitations}
\begin{itemize}
    \item \textbf{No Unified Framework}: There is an absence of a unified comparison framework for factual consistency.
    \item \textbf{Scaling Isn't a Silver Bullet}: Simply scaling up model sizes does not necessarily improve their truthfulness.
    \item \textbf{Estimator Performance}: Current estimators designed to measure factuality (like FActScore) still have limitations in effectively addressing the task.
    \item \textbf{Hallucination Risk}: Models are capable of generating coherent-sounding text that includes factual inaccuracies, making detection difficult.
\end{itemize}


\subsubsection{Additional References}

This metric is referenced and/or used in the following paper(s):


\sloppy
\cite{
Chang2023SurveyLLMs,
lin2021truthfulqa,
wang2023evaluating,
min2023factscore,
honovich2022true,
gekhman2023trueteacher,
manakul2023selfcheckgpt,
}
\fussy
