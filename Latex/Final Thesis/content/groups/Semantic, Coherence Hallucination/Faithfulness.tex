\subsection{Faithfulness (Design Fidelity)}

Faithfulness is an evaluation metric used within the \textbf{DevEval} benchmark to measure ``Design Fidelity.'' It is not a single score but a principle of evaluation, specifically assessing the extent to which a Large Language Model (LLM) adheres to specified instructions when generating software design artifacts.

The core idea is to measure how accurately and strictly the model's output (e.g., UML diagrams, architecture design) aligns with the given \textbf{Product Requirement Document (PRD)}, ensuring all functionalities are met ``without making any hallucinations and additions.'' This metric is typically assessed using an ``LLM-as-a-judge'' approach.

\subsubsection*{Evaluation Methods}
Faithfulness is evaluated differently across the sub-tasks of software design:

\begin{itemize}
    \item \textbf{For UML Class Diagrams}: The metric evaluates if the generated conceptual classes, their relationships (inheritance, aggregation, composition), cardinalities, and class names ``accurately represent the essentials outlined in the PRD.''
    \item \textbf{For UML Sequence Diagrams}: The evaluation checks how ``accurately and comprehensively'' the diagram reflects the system's intended behavior as specified in the PRD. This includes capturing system events and ensuring the design is coherent with the class diagrams.
    \item \textbf{For Architecture Design}: The metric verifies that the file tree structure is in ``strict accordance with the given PRD and UML class diagrams,'' ensuring a consistent development process.
\end{itemize}

\subsubsection*{Purpose}
The purpose of the Faithfulness metric is to quantify a model's ability to \textbf{strictly follow detailed, document-level requirements} and translate them into accurate, corresponding design artifacts. This measures a critical component of design fidelity beyond just generating plausible-sounding designs.

\subsubsection{Applications}

The Faithfulness (Design Fidelity) metric is primarily applied during the \textbf{Software Design} phase of the Software Development Lifecycle (SDLC). Its main utility lies in automating and validating the conversion of natural language requirements into technical blueprints, ensuring that generative models act as reliable architects rather than creative writers \cite{Li2024FullSDLC}.

Key applications include:

\begin{itemize}
    \item \textbf{Automated System Modeling}: The metric is essential for tools that automatically generate \textbf{UML Class and Sequence Diagrams} from Product Requirement Documents (PRDs). It ensures that the generated diagrams strictly adhere to the specified classes, relationships (inheritance, composition), and interaction flows, preventing the inclusion of hallucinated features that were not requested by stakeholders.

    \item \textbf{Architectural Scaffolding}: In the generation of project skeletons, this metric is applied to verify that the proposed \textbf{File Tree Structure} aligns perfectly with the logical design. It ensures that the file hierarchy (directories, module names) is a faithful translation of the architecture derived from the PRD, facilitating a consistent setup for the implementation phase.

    \item \textbf{Requirement Traceability \& Auditing}: Faithfulness serves as an automated quality gate. By using an "LLM-as-a-judge" to penalize additions and hallucinations, it helps establish a clear chain of custody from requirement to design. This application is critical for safety-critical software where every design element must be traceable back to a specific user requirement without unauthorized deviations.
\end{itemize}

\subsubsection*{Advantages}
\begin{itemize}
    \item \textbf{Real-World Relevance}: Measures a crucial software engineering skill: adherence to specifications.
    \item \textbf{Hallucination Control}: Directly targets and penalizes model hallucinations or unrequested feature additions.
    \item \textbf{Scope Expansion}: Moves evaluation beyond simple code generation to the critical upstream phase of design planning.
\end{itemize}

\subsubsection*{Limitations}
\begin{itemize}
    \item \textbf{Dependency on Judges}: The metric relies on an ``LLM-as-a-judge'' for evaluation, which may introduce its own biases or inconsistencies.
    \item \textbf{Subjectivity}: It is largely a subjective assessment of alignment rather than a strictly quantitative, replicable numerical score.
\end{itemize}


\subsubsection{Additional References}

This metric is referenced and/or used in the following paper(s):


\sloppy
\cite{
Li2024FullSDLC,
}
\fussy
