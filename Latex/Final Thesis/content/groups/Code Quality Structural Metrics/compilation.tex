\subsection{Compilation Metrics}

Compilation metrics evaluate whether code generated by a Large Language Model (LLM) can be successfully compiled or interpreted without producing syntax or structural errors. This is a foundational step in code evaluation pipelines: if the code does not compile, it cannot be tested for functional correctness.

Two primary sources define compilation-based evaluation:
\begin{itemize}
    \item \textit{A Survey on Evaluating Large Language Models in Code Generation Tasks (2024)} \cite{Chen2024SurveyCodeGen}
    \item \textit{LoCoBench: A Long-Context Benchmark for Software Engineering Tasks (2025)} \cite{Qiu2025LoCoBench}
\end{itemize}
Both emphasize that compilation success is an essential, low-cost, and objective measurement of syntactic validity.

Compilation metrics answer a single question:
\textit{Does the generated code conform to the syntactic and structural rules of the language such that it can compile or interpret without errors?}

A successful compilation ensures:
\begin{itemize}
    \item Valid syntax
    \item Correct use of language constructs
    \item No missing brackets, indentation errors, or malformed expressions
    \item No unresolved symbols or syntactic mismatches
\end{itemize}
A failed compilation indicates structural or syntactic issues that prevent execution.

Although not presented as equations in the papers, compilation metrics follow a clear binary structure.

For each generated sample:
\begin{equation}
\text{Compilation Success} =
\begin{cases}
1 & \text{if the code compiles successfully} \\
0 & \text{otherwise}
\end{cases}
\end{equation}

Across $N$ generated samples, the \textit{Compilation Success Rate (CSR)} is:

\begin{equation}
\text{CSR} = \frac{\text{Number of successfully compiled samples}}{N}
\end{equation}

This is the standard formulation used in execution-based evaluation frameworks.

\subsubsection{Compilation in Evaluation Frameworks}

\textbf{In the 2024 Survey} \\
Compilation is identified as a core execution-based metric that validates code before running unit tests \cite{Chen2024SurveyCodeGen}.
The survey discusses systems designed to improve compilation outcomes:
\begin{itemize}
    \item \textit{FRANC}: Combines static analysis and compiler feedback to improve compilation rates.
    \item \textit{COMPCODER}: Uses compiler error messages iteratively to refine code.
\end{itemize}
Reported improvements:
\begin{itemize}
    \item Java compilation rates: +9\% to +46\%
    \item Python compilation rates: +10\% to +43\%
\end{itemize}
This demonstrates the importance of compilation checks in LLM code generation.

\textbf{In LoCoBench (2025)} \\
LoCoBench introduces \textit{Code Compilation Success (CCS)} as part of its functional correctness dimension \cite{Qiu2025LoCoBench}.
Key insights:
\begin{itemize}
    \item CCS is a \textit{binary syntactic validity metric}.
    \item Long-context code often risks structural drift; CCS detects this early.
    \item LLMs evaluated achieved \textit{98.7\% CCS}, indicating strong syntactic reliability, even under long-context scenarios.
\end{itemize}

CCS is used alongside Unit Test Performance (UTP) and Integration Test Performance (ITP) to build a full correctness profile \cite{Qiu2025LoCoBench}.

\subsubsection{Why Compilation Metrics Matter}

Compilation-based evaluation is crucial because:
\begin{itemize}
    \item If code fails to compile, deeper evaluation is impossible.
    \item It provides a fast, objective measure of whether a model respects language syntax.
    \item It reduces computational overhead by filtering invalid outputs before unit testing.
    \item Compilation errors correlate strongly with deeper structural and semantic issues.
\end{itemize}

Thus, compilation functions as the primary gatekeeper in code evaluation pipelines. It establishes a hierarchical validation process where syntactic integrity is a prerequisite for any further analysis:
\begin{enumerate}
    \item \textbf{Syntactic Validation (Compilation):} The initial filter for execution viability.
    \item \textbf{Functional Validation (Unit Tests):} Assessment of internal logic.
    \item \textbf{Systemic Validation (Integration Tests):} Evaluation of cross-component behavior.
\end{enumerate}
Under this framework, only code that successfully passes the compilation stage is considered eligible for deeper functional testing, ensuring that evaluation resources are focused exclusively on viable candidates.