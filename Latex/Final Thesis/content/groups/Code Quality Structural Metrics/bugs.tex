\subsection{Bug Metrics}

Bug Metrics, in the context of this study, refer to software attributes used to predict whether a class will contain defects. Rather than capturing detection or localization accuracy, the paper used as reference evaluates a set of static source-code metrics that statistically correlate with defect occurrence in large software systems \cite{Rebro2023SourceCodeMetrics}.
These metrics quantify class characteristics such as size (LOC), complexity (WMC, NLE), inheritance structure (DIT, NOC), data and method exposure (NPA, NPM), coupling (CBO, CBOI), cohesion (LCOM5), and documentation quality (CD).
The authors analyze 12 such metrics over 275 versions of 39 Java projects, linking them to class-level defect labels extracted from GitHub commits. Together, these metrics serve as bug metrics in the sense that they help identify which classes are most defect-prone \cite{Rebro2023SourceCodeMetrics}.

The paper does not define a general mathematical formula. Instead, each metric is computed directly from its structural definition. For example:

\begin{itemize}
    \item \textbf{LOC:} Number of code lines excluding nested, anonymous, and local classes.
    \item \textbf{DIT (Depth of Inheritance Tree):} Distance to the farthest ancestor.
    \item \textbf{NOC (Number of Children):} Count of all direct subclasses, interfaces, enums, and annotations.
    \item \textbf{LCOM5 (Lack of Cohesion in Methods):} Number of distinct functionalities represented by the classâ€™s methods.
    \item \textbf{CBO / CBOI (Coupling):} Outgoing vs. incoming coupling based on referenced or referencing classes.
    \item \textbf{CD (Comment Density):} Ratio of comment lines to total logical lines.
\end{itemize}

The metrics are then used as features in a binary classification model predicting whether each class is defective or not defective. Prediction performance is evaluated using standard classification metrics (F-measure, AUC-ROC) at the class level \cite{Rebro2023SourceCodeMetrics}.

\subsubsection{Variants and Applications}

\textbf{Metric Suites} \\
The paper evaluates three structured groups of bug-related metrics \cite{Rebro2023SourceCodeMetrics}:
\begin{enumerate}
    \item \textbf{Baseline Metric}
    \begin{itemize}
        \item \textbf{LOC:} Serves as a simple defect indicator due to correlation between class size and fault-proneness.
    \end{itemize}
    \item \textbf{CK Metric Suite (Chidamber \& Kemerer)}
    \begin{itemize}
        \item \textbf{DIT, NOC, LCOM5, CBO:} Widely used in defect prediction literature; designed to capture structural aspects of OO classes such as complexity, inheritance, cohesion, and coupling.
    \end{itemize}
    \item \textbf{OTHER Metrics Suite}
    \begin{itemize}
        \item \textbf{NPA, NPM, NLE, CBOI, CD:} Additional metrics selected because they introduce information not strongly correlated with the CK suite.
    \end{itemize}
\end{enumerate}

\textbf{Use in Defect Prediction}
\begin{itemize}
    \item Metrics are computed at the class level using static analysis.
    \item Defects are linked to classes using commit messages and code diff analysis.
    \item Models evaluated: Naive Bayes, Decision Tree, Random Forest.
    \item Prediction is performed using 10-fold cross-validation.
    \item Metrics with high multicollinearity (RFC, WMC) are removed from feature-importance analysis via the Variation Inflation Factor (VIF) threshold of 2.5.
\end{itemize}

These applications allow assessing which aspects of the codebase are most informative for predicting defects, and which provide little added value.

\subsubsection{Interpretation}

The analysis reveals strong, consistent trends in how different structural metrics contribute to predicting defects \cite{Rebro2023SourceCodeMetrics}:

\textbf{Strong Predictors of Defect-Proneness}
\begin{itemize}
    \item \textbf{NOC (Number of Children):} \textit{Most consistently top-ranked.} High inheritance branching correlates with higher defect likelihood.
    \item \textbf{NPA (Number of Public Attributes):} Suggests that high data exposure increases the chance of faulty behavior.
    \item \textbf{DIT (Depth of Inheritance Tree):} Deep hierarchies can increase complexity and error propagation.
    \item \textbf{LCOM5 (Lack of Cohesion):} Poor cohesion typically reflects scattered responsibilities and higher fault risk.
\end{itemize}
These metrics tend to capture structural complexity and encapsulation quality, which strongly influence defect incidence.

\textbf{Weak Predictors}
\begin{itemize}
    \item \textbf{CBO (Coupling):} Surprisingly performs the worst in most projects.
    \item \textbf{CD (Comment Density):} Documentation level does not reliably correlate with defects in this dataset.
    \item \textbf{NPM (Number of Public Methods):} Larger APIs appear less predictive of faults than expected.
\end{itemize}

\textbf{Model Behavior}
\begin{itemize}
    \item Decision Tree (DT) and Random Forest (RF) consistently outperform Naive Bayes in both F-measure and AUC-ROC.
    \item The combination of CK + OTHER metrics produces the most stable prediction performance.
    \item LOC alone is a weak predictor, confirming that structural complexity beyond size is essential for accurate defect prediction \cite{Rebro2023SourceCodeMetrics}.
\end{itemize}

Overall, the study demonstrates that inheritance-related metrics (NOC, DIT), encapsulation metrics (NPA), and cohesion (LCOM5) carry the highest diagnostic value for identifying defect-prone classes in Java projects.