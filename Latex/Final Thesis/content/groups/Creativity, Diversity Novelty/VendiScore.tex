\subsection{Vendi Score}

The \textbf{Vendi Score (VS)} is a metric used to evaluate the \textbf{diversity} of samples produced by a generative model. Introduced by Friedman and Dieng (2022), it is heavily utilized in recent analyses (e.g., Stein et al., 2023) to assess inter- vs. intra-class diversity.

The Vendi Score is a ``reference-free'' metric, meaning it does not require a set of real images for comparison. Instead, it quantifies diversity by calculating the ``effective number of unique samples'' within a given set of generated images. A higher Vendi Score indicates greater diversity.

The Vendi Score is computed using the eigenvalues of a similarity matrix (kernel) $K$ derived from the generated samples $x_i^g$. The formula represents the exponential of the Shannon entropy of the eigenvalues:

\begin{equation}
    VS(\{x_i^g\}_{i=1}^n) = \exp\left(-\sum_{i=1}^n \lambda_i \log \lambda_i\right)
\end{equation}

\noindent where:
\begin{itemize}
    \item $\lambda_i$: The $i$-th eigenvalue of the normalized kernel matrix $K/n$.
    \item $K_{ii'} = k(x_i^g, x_{i'}^g)$: The similarity (kernel) between two samples (typically a linear or RBF kernel).
\end{itemize}

\subsubsection*{1. Vendi Score (Overall)}
\textbf{Definition} \\
The Overall Vendi Score is calculated across an entire set of generated samples (e.g., 50,000 images) from all classes simultaneously.

\textbf{Purpose \& Limitations} \\
This metric reports the overall sample diversity. In class-conditional models, it primarily measures \textbf{inter-class diversity} (variety between classes). However, it is considered ``not particularly meaningful'' for these models because a model could achieve a high score simply by generating one distinct sample per class while failing to create variety \textit{within} those classes.

\subsubsection*{2. Vendi Score (Per-Class)}
\textbf{Definition} \\
The Per-Class Vendi Score is computed independently for \textbf{each class} in the dataset (e.g., separately for "volcano" images, "comic book" images, etc.), and the final metric is the average of these individual scores.

\textbf{Purpose \& Advantages} \\
This metric quantifies \textbf{intra-class diversity} (or ``semantic diversity''). It measures how much variety a model produces \textit{within} a single category. Stein et al. (2023) advocate for this variant as a ``more meaningful quantification of semantic diversity,'' noting that it aligns better with visual inspection than the Overall score.

\begin{table}[H]
    \centering
    \caption{Comparison of Vendi Score Variants}
    \label{tab:vendi_variants}
    \begin{tabular}{|p{3cm}|p{3.5cm}|p{3.5cm}|p{3cm}|}
    \hline
    \textbf{Metric} & \textbf{Calculation Basis} & \textbf{What It Measures} & \textbf{Utility} \\
    \hline
    Vendi Score (Overall) & Entire dataset (all classes mixed) & Inter-class diversity & Can be misleading \\
    \hline
    Vendi Score (Per-Class) & Averaged scores from within each class & Intra-class diversity (semantic) & Recommended / Robust \\
    \hline
    \end{tabular}
\end{table}

\subsubsection{Applications in Software Engineering}

While originally demonstrated on image, text, and molecular data, the Vendi Score's flexible definition of similarity makes it highly relevant for Software Engineering (SE) tasks, particularly those involving Generative AI and Large Language Models (LLMs).

\begin{itemize}
    \item \textbf{Code Generation Diversity:} In automated code generation, diversity is crucial for exploring different implementation strategies or algorithmic solutions for a single problem specification. The Vendi Score can evaluate the diversity of code snippets generated by LLMs by using similarity kernels based on $n$-gram overlap or embedding cosine similarity (e.g., CodeBERT) \cite{friedman2022vendi}.
    
    \item \textbf{Test Case Generation:} Effective software testing requires diverse test inputs to maximize code coverage and edge-case detection. The Vendi Score can quantify the diversity of generated test suites without needing a reference distribution, helping to identify redundant test cases \cite{friedman2022vendi}.
    
    \item \textbf{Data Augmentation for SE Models:} When training models for tasks like bug detection or code summarization, data augmentation is often used to expand limited datasets. The Vendi Score can diagnose the diversity of augmented datasets to ensure that the augmentation strategies are introducing genuine variety rather than mere duplicates \cite{friedman2022vendi}.
    
    \item \textbf{Evaluating Decoding Algorithms:} Friedman and Dieng demonstrated the use of VS to evaluate text decoding algorithms (e.g., beam search vs. diverse beam search). This is directly applicable to SE interfaces, such as coding assistants, where users benefit from a diverse list of potential code completions (``Diverse N-Best List'') rather than repetitive suggestions \cite{friedman2022vendi}.
\end{itemize}


\subsubsection{Additional References}

This metric is referenced and/or used in the following paper(s):


\sloppy
\cite{
Stein2023MetricFlaws,
friedman2022vendi,
}
\fussy


