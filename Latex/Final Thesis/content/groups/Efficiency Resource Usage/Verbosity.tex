\subsection{Verbosity}

\subsubsection*{Definition}
\textbf{Verbosity} is a metric used in code generation evaluation to measure the ``wordiness'' or excessive length of a Large Language Model's (LLM) output.

It is typically treated as a trade-off against functional performance, where high verbosity is considered a negative characteristic, even if the model's output is functionally correct.

\subsubsection*{Purpose}
The purpose of measuring verbosity is to assess the practical utility and ``communication clarity'' of an LLM. Models that are overly verbose may provide correct answers but are less efficient for developers, who must read and parse the unnecessarily long output. It highlights the balance between raw performance and conciseness.

\subsubsection*{Domains}
\begin{itemize}
    \item Software Engineering
    \item Code Generation
    \item LLM Evaluation
\end{itemize}

\subsubsection{Applications in Software Engineering}

In the domain of automated code generation, **Verbosity** is not merely a stylistic metric but a critical factor in evaluating the developer experience and the practical efficiency of Large Language Models (LLMs).

\begin{itemize}
    \item \textbf{Trade-off Analysis in Model Selection}: \\
    Software engineers use verbosity metrics to navigate the trade-offs between model accuracy and usability. Bistarelli et al. highlight that while top-tier models like OpenAI's o1-preview and o1-mini lead the leaderboards in functional correctness for languages like Java, Go, and Ruby, they simultaneously exhibit significantly higher verbosity compared to competitors \cite{Bistarelli2025UsageLLMCode}. This application of the metric allows engineering teams to decide whether the cost of parsing "wordy" outputs is justified by the marginal gains in code accuracy.

    \item \textbf{Developer Efficiency and Communication Clarity}: \\
    High verbosity directly impacts the "communication clarity" of a coding assistant. In real-world software development workflows, developers must review and integrate generated code. Excessive verbosity increases the cognitive load and time required for this review process \cite{Bistarelli2025UsageLLMCode}. Therefore, measuring verbosity serves as a proxy for the \textit{usability} of an LLM, guiding the selection of models that provide concise, actionable code snippets rather than lengthy, conversational explanations that clutter the development environment.
\end{itemize}

\subsubsection*{Key Findings \& Trade-offs}
Recent comprehensive evaluations (e.g., of over 80 LLMs) have identified a clear trade-off between capability and brevity:
\begin{itemize}
    \item Top performers in functional correctness (such as \textbf{OpenAI o1-preview}, \textbf{o1-mini}, and \textbf{Anthropic Claude 3.5 Sonnet}) often exhibit ``significantly higher latency and verbosity.''
    \item This demonstrates that achieving high reasoning performance often currently comes at the cost of less concise communication.
\end{itemize}

\subsubsection{Additional References}

This metric is referenced and/or used in the following paper(s):


\sloppy
\cite{
Bistarelli2025UsageLLMCode,
}
\fussy
