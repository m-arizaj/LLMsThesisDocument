\subsection{Inference (Efficiency and Verification)}

In the evaluation of Large Language Models (LLMs) and the systems they generate, ``Inference'' describes metrics in two distinct categories:

\begin{itemize}
    \item \textbf{Inference Efficiency}: The performance of a model during the generation phase (speed, resource consumption, runtime).
    \item \textbf{Behavioral Model Inference}: A specialized verification metric in Software Engineering referring to the success rate of automatically learning a correct behavioral model (e.g., an automaton) to validate functional correctness.
\end{itemize}

\subsubsection*{1. Inference Efficiency (Runtime / Speed)}

\textbf{Definition} \\
Inference Efficiency metrics measure the computational cost and speed of a language model when performing its primary function: generating text. HELM (Holistic Evaluation of Language Models) proposes several specific metrics:
\begin{itemize}
    \item \textbf{Raw Runtime}: Actual wall-clock time including network noise.
    \item \textbf{Denoised Inference Runtime}: Estimated runtime with contention (queuing) noise factored out.
    \item \textbf{Idealized Inference Runtime}: A standardized metric estimating runtime on a uniform, optimized hardware stack (e.g., NVIDIA A100) for fair comparison.
\end{itemize}

\textbf{Formula (HELM Idealized Runtime)} \\
The total time for an idealized runtime is modeled as a function of prompt processing time and token generation time:

\begin{equation}
    \text{Total Time} = F(N_{\text{prompt}}) + g \cdot N_{\text{output}}
\end{equation}

\noindent where:
\begin{itemize}
    \item $F$: Function modeling the runtime of processing the prompt tokens ($N_{\text{prompt}}$).
    \item $g$: Runtime (cost) of generating each additional output token.
    \item $N_{\text{output}}$: Number of output tokens generated.
\end{itemize}

\textbf{Purpose} \\
To measure the practical performance of an LLM. High efficiency is critical for user-facing applications (chatbots) and autonomous agents requiring fast responses.

\textbf{Limitations} \\
Comparing efficiency is difficult due to non-model factors like hardware types (GPUs/TPUs), software optimizations, and API server contention.

\subsubsection*{2. Behavioral Model Inference (Success Rate)}

\textbf{Definition} \\
Specific to Learning-Based Testing and Language-Driven Engineering (LDE), this metric does \textbf{not} measure computational speed. Instead, it measures the \textbf{success rate (\%)} of automatically \textit{inferring} a correct behavioral model (e.g., a Mealy machine) from a generated application.

For example, in system migration (e.g., JS to TS), a tool tests the resulting application to infer its behavior. The success rate reflects whether this inferred model is correct, validating the migration.

\textbf{Purpose} \\
To automatically validate functional correctness and reliability. It verifies that the generated system behaves as intended or identifies behavioral differences using ``difference automata.''

\subsubsection*{Comparative Summary}
\begin{table}[H]
    \centering
    \caption{Comparative Summary of Inference and Behavioral Metrics}
    \label{tab:inference_metrics}
    \begin{tabular}{|p{3cm}|p{2.5cm}|p{5cm}|p{2.5cm}|}
    \hline
    \textbf{Metric Category} & \textbf{Measures} & \textbf{Description} & \textbf{Typical Domain} \\
    \hline
    Inference Efficiency & Efficiency & Computational cost, time (s), or tokens/sec during text generation. & LLM Evaluation, Agents \\
    \hline
    Behavioral Model Inference & Verification & Success rate (\%) of automatically deriving a correct behavioral automaton from a system. & Software Engineering, LDE \\
    \hline
    \end{tabular}
\end{table}

\subsubsection{Applications in Software Engineering}

The dual interpretation of ``Inference''as both a performance metric (Efficiency) and a verification method (Behavioral Learning) enables critical applications in modern software engineering, particularly for LLM-based systems.

\begin{itemize}
    \item \textbf{Automated Validation of System Migration (Behavioral Inference)}: \\
    In the context of Language-Driven Engineering (LDE), Behavioral Model Inference is applied to validate the migration of legacy systems. Busch et al. demonstrate this by migrating a web-based point-and-click adventure game from JavaScript to TypeScript using LLMs \cite{Busch2025LLMCodeMigration}. By employing \textit{active automata learning}, engineers can infer behavioral models (Mealy machines) of both the original and the migrated system. This process allows for the generation of \textbf{difference automata}, which strictly characterize behavioral discrepancies between the two versions, ensuring that the LLM-generated code preserves the intended functionality without manual testing \cite{Busch2025LLMCodeMigration}.

    \item \textbf{Resource-Constrained Autonomous Agents (Inference Efficiency)}: \\
    For LLM-based autonomous agents, Inference Efficiency is a defining constraint for architectural viability. Agents acting in dynamic environments often rely on complex planning modules (e.g., Chain of Thought or Tree of Thoughts) and extensive memory retrieval operations, which require multiple inference calls per action \cite{Wang2024AutonomousAgentsSurvey}. High inference latency or cost can render an agent impractical for real-time tasks. Consequently, efficiency metrics are used to balance the trade-off between an agent's reasoning depth (capability) and its response time (usability) \cite{Wang2024AutonomousAgentsSurvey}.

    \item \textbf{Benchmarking for User-Facing Deployments (Inference Efficiency)}: \\
    In the deployment of foundational models, Inference Efficiency dictates the feasibility of user-facing applications, such as chatbots or mobile assistants. Liang et al. utilize efficiency metrics (specifically \textit{Idealized Inference Runtime}) to normalize comparisons across disparate hardware configurations \cite{Liang2022HELM}. This application allows software engineers to select models that maximize accuracy while remaining within the strict latency budgets required for interactive user experiences \cite{Liang2022HELM}.
\end{itemize}

\subsubsection{Additional References}

This metric is referenced and/or used in the following paper(s):


\sloppy
\cite{
Busch2025LLMCodeMigration,
Liang2022HELM,
Wang2024AutonomousAgentsSurvey,
}
\fussy
