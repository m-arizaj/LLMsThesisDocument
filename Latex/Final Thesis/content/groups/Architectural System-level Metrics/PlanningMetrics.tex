\subsection{Planning Metrics}

\subsubsection*{Introduction}
In the context of LLM-based autonomous agents, \textbf{planning} is a critical capability that allows an agent to deconstruct a complex task into simpler, solvable subtasks. This module is essential for making agents ``behave more reasonably, powerfully, and reliably.''

To evaluate how well an agent formulates these plans, specific metrics are used. These generally fall into two categories: \textbf{efficiency metrics} (cost/length) and \textbf{output quality metrics} (correctness/similarity). This document covers two key metrics: \textbf{Length of Planning} and \textbf{Plan Score}.

\subsubsection*{1. Length of Planning}

\textbf{Definition} \\
Length of Planning is an objective evaluation metric used to assess the \textbf{efficiency} of an autonomous agent. It is defined as the number of steps, operations, or reasoning steps an agent includes in its generated plan to accomplish a task.

\textbf{Purpose} \\
The primary purpose is to quantify the efficiency of an agent's reasoning process. Generally, a plan with fewer steps is considered more efficient (assuming success). It is often measured alongside development cost and inference speed.

\textbf{Applications} \\
\begin{itemize}
    \item \textbf{LLM Agents}: Used in objective evaluation protocols.
    \item \textbf{Task Planning}: Comparing the conciseness of plans generated by different agents.
\end{itemize}

\textbf{Limitations} \\
This metric only measures efficiency (length) and does not, by itself, measure the correctness or quality of the plan. A short plan is useless if it fails to solve the task.

\subsubsection*{2. Plan Score}

\textbf{Definition} \\
Plan Score is an objective metric introduced in the \textbf{T-Eval} benchmark to evaluate the \textbf{output quality} of an agent's plan. It measures the similarity between the agent's predicted plan and a ``gold answer'' (a human-annotated correct plan).

\textbf{Formula} \\
The score is calculated based on the F1-score of precision and recall, derived from the longest common subsequence of actions. The process involves:

1. \textbf{Similarity Matrix ($S$)}: Computed for all action pairs $(a_i, a_j)$ considering both the tool and its arguments.
\begin{equation}
    S_{i,j} = \beta \sigma(\text{tool}_i, \text{tool}_j) + (1-\beta) \sigma(\text{args}_i, \text{args}_j)
\end{equation}

2. \textbf{Longest Subsequence ($l$)}: The Longest Increasing Subsequence (LIS) algorithm is used on matrix $S$ to find the length $l$.

3. \textbf{Precision ($p$) and Recall ($r$)}: Calculated based on $l$ and the lengths of the predicted ($n_{pred}$) and gold ($n_{gt}$) plans.
\begin{equation}
    p = \frac{l}{n_{pred}}, \quad r = \frac{l}{n_{gt}}
\end{equation}

4. \textbf{Plan Score}: The harmonic mean.
\begin{equation}
    \text{planscore} = \frac{2pr}{p+r}
\end{equation}

\textbf{Purpose} \\
To quantify the quality of a generated plan, rewarding agents that produce plans structurally and functionally similar to a human-annotated correct solution.

\textbf{Applications} \\
\begin{itemize}
    \item \textbf{T-Eval Benchmark}: Core component for evaluating tool utilization.
    \item \textbf{Multi-step Tasks}: Evaluating plans in multi-tool scenarios.
\end{itemize}

\textbf{Limitations} \\
\begin{itemize}
    \item Requires a ``gold answer'' for comparison, making it difficult to use in open-ended scenarios where multiple distinct plans could be correct.
    \item Computationally complex due to similarity matching and subsequence algorithms.
\end{itemize}

\subsubsection*{Comparative Summary}
Below is a comparison of the efficiency and quality metrics for planning:

\begin{center}
\begin{tabular}{|p{2.5cm}|p{2.5cm}|p{4cm}|p{2cm}|p{2cm}|}
\hline
\textbf{Metric} & \textbf{Primary Goal} & \textbf{How it Works} & \textbf{Category} & \textbf{Gold Std?} \\
\hline
Length of Planning & Measure plan efficiency & Counts the number of steps in the generated plan. & Efficiency & No \\
\hline
Plan Score & Measure plan quality \& correctness & Calculates F1-score based on similarity (tool \& args) to a gold plan. & Output Quality & Yes \\
\hline
\end{tabular}
\end{center}


\subsubsection{Additional References}

This metric is referenced and/or used in the following paper(s):


\sloppy
\cite{
Wang2024AutonomousAgentsSurvey,
Xu2025LLMAgentsToolLearning,
chen2023teval,  
Liu2023LLMP,
}
\fussy
